{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QgNbg-furHwR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as td\n",
        "from tensorflow import keras\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Dict\n",
        "# getting the data\n",
        "\n",
        "data = keras.datasets.imdb\n",
        "\n",
        "# split the data to train & test set\n",
        "\n",
        "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words= 10000) # taking the 10,000 most commen words\n",
        "\n",
        "# every number in the data represent a word, so to see the words we need to connect the numbers to the words dictionary\n",
        "word_index = data.get_word_index()\n",
        "\n",
        "\n",
        "word_index = {k:(v+3) for k,v in word_index.items()}\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNK>\"] = 2  # unknown\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# this function will return the decoded (human readable) reviews\n",
        "def decode_review(text):\n",
        "\treturn \" \".join([reverse_word_index.get(i, \"?\") for i in text])\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=word_index[\"<PAD>\"], padding=\"post\", maxlen=250)\n"
      ],
      "metadata": {
        "id": "kz5ibZsQ2Sx4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the model\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Embedding(88000, 16))\n",
        "model.add(keras.layers.GlobalAveragePooling1D())\n",
        "model.add(keras.layers.Dense(16, activation=\"relu\"))\n",
        "model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()  # prints a summary of the model\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "x_val = train_data[:10000]\n",
        "x_train = train_data[10000:]\n",
        "\n",
        "y_val = train_labels[:10000]\n",
        "y_train = train_labels[10000:]\n",
        "\n",
        "fitModel = model.fit(x_train, y_train, epochs= 40, batch_size = 512, validation_data = (x_val, y_val), verbose = 1)\n",
        "\n",
        "results = model.evaluate(test_data, test_labels)\n",
        "\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSYvWdatB_Wy",
        "outputId": "ffc4ea77-e695-4a92-803c-b4ad472f9957"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 16)          1408000   \n",
            "                                                                 \n",
            " global_average_pooling1d_3  (None, 16)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1408289 (5.37 MB)\n",
            "Trainable params: 1408289 (5.37 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/40\n",
            "30/30 [==============================] - 2s 39ms/step - loss: 0.6920 - accuracy: 0.6169 - val_loss: 0.6900 - val_accuracy: 0.6512\n",
            "Epoch 2/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.6863 - accuracy: 0.6515 - val_loss: 0.6820 - val_accuracy: 0.7350\n",
            "Epoch 3/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.6733 - accuracy: 0.7483 - val_loss: 0.6652 - val_accuracy: 0.7533\n",
            "Epoch 4/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.6490 - accuracy: 0.7749 - val_loss: 0.6370 - val_accuracy: 0.7709\n",
            "Epoch 5/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.6127 - accuracy: 0.7911 - val_loss: 0.5991 - val_accuracy: 0.7888\n",
            "Epoch 6/40\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.5668 - accuracy: 0.8131 - val_loss: 0.5544 - val_accuracy: 0.8037\n",
            "Epoch 7/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.5165 - accuracy: 0.8297 - val_loss: 0.5088 - val_accuracy: 0.8218\n",
            "Epoch 8/40\n",
            "30/30 [==============================] - 1s 34ms/step - loss: 0.4671 - accuracy: 0.8506 - val_loss: 0.4658 - val_accuracy: 0.8353\n",
            "Epoch 9/40\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.4225 - accuracy: 0.8631 - val_loss: 0.4297 - val_accuracy: 0.8448\n",
            "Epoch 10/40\n",
            "30/30 [==============================] - 1s 49ms/step - loss: 0.3840 - accuracy: 0.8747 - val_loss: 0.4000 - val_accuracy: 0.8534\n",
            "Epoch 11/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.3522 - accuracy: 0.8853 - val_loss: 0.3761 - val_accuracy: 0.8594\n",
            "Epoch 12/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.3253 - accuracy: 0.8926 - val_loss: 0.3575 - val_accuracy: 0.8654\n",
            "Epoch 13/40\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.3029 - accuracy: 0.8973 - val_loss: 0.3433 - val_accuracy: 0.8680\n",
            "Epoch 14/40\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.2840 - accuracy: 0.9022 - val_loss: 0.3303 - val_accuracy: 0.8738\n",
            "Epoch 15/40\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.2669 - accuracy: 0.9090 - val_loss: 0.3203 - val_accuracy: 0.8768\n",
            "Epoch 16/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.2519 - accuracy: 0.9133 - val_loss: 0.3124 - val_accuracy: 0.8781\n",
            "Epoch 17/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.2386 - accuracy: 0.9169 - val_loss: 0.3062 - val_accuracy: 0.8794\n",
            "Epoch 18/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.2267 - accuracy: 0.9212 - val_loss: 0.3009 - val_accuracy: 0.8819\n",
            "Epoch 19/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.2152 - accuracy: 0.9254 - val_loss: 0.2974 - val_accuracy: 0.8820\n",
            "Epoch 20/40\n",
            "30/30 [==============================] - 1s 46ms/step - loss: 0.2055 - accuracy: 0.9295 - val_loss: 0.2932 - val_accuracy: 0.8837\n",
            "Epoch 21/40\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.1954 - accuracy: 0.9333 - val_loss: 0.2905 - val_accuracy: 0.8846\n",
            "Epoch 22/40\n",
            "30/30 [==============================] - 1s 44ms/step - loss: 0.1867 - accuracy: 0.9380 - val_loss: 0.2882 - val_accuracy: 0.8847\n",
            "Epoch 23/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1783 - accuracy: 0.9417 - val_loss: 0.2871 - val_accuracy: 0.8843\n",
            "Epoch 24/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1707 - accuracy: 0.9462 - val_loss: 0.2866 - val_accuracy: 0.8851\n",
            "Epoch 25/40\n",
            "30/30 [==============================] - 1s 40ms/step - loss: 0.1638 - accuracy: 0.9483 - val_loss: 0.2862 - val_accuracy: 0.8850\n",
            "Epoch 26/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.1566 - accuracy: 0.9508 - val_loss: 0.2855 - val_accuracy: 0.8862\n",
            "Epoch 27/40\n",
            "30/30 [==============================] - 1s 38ms/step - loss: 0.1499 - accuracy: 0.9540 - val_loss: 0.2856 - val_accuracy: 0.8858\n",
            "Epoch 28/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.1439 - accuracy: 0.9567 - val_loss: 0.2865 - val_accuracy: 0.8852\n",
            "Epoch 29/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1390 - accuracy: 0.9573 - val_loss: 0.2876 - val_accuracy: 0.8856\n",
            "Epoch 30/40\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.1325 - accuracy: 0.9607 - val_loss: 0.2885 - val_accuracy: 0.8853\n",
            "Epoch 31/40\n",
            "30/30 [==============================] - 1s 37ms/step - loss: 0.1276 - accuracy: 0.9627 - val_loss: 0.2903 - val_accuracy: 0.8865\n",
            "Epoch 32/40\n",
            "30/30 [==============================] - 1s 48ms/step - loss: 0.1221 - accuracy: 0.9651 - val_loss: 0.2926 - val_accuracy: 0.8853\n",
            "Epoch 33/40\n",
            "30/30 [==============================] - 1s 47ms/step - loss: 0.1171 - accuracy: 0.9663 - val_loss: 0.2938 - val_accuracy: 0.8863\n",
            "Epoch 34/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.1125 - accuracy: 0.9678 - val_loss: 0.2967 - val_accuracy: 0.8857\n",
            "Epoch 35/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.1083 - accuracy: 0.9693 - val_loss: 0.2987 - val_accuracy: 0.8852\n",
            "Epoch 36/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.1041 - accuracy: 0.9719 - val_loss: 0.3017 - val_accuracy: 0.8847\n",
            "Epoch 37/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.1002 - accuracy: 0.9727 - val_loss: 0.3051 - val_accuracy: 0.8842\n",
            "Epoch 38/40\n",
            "30/30 [==============================] - 1s 36ms/step - loss: 0.0963 - accuracy: 0.9748 - val_loss: 0.3083 - val_accuracy: 0.8833\n",
            "Epoch 39/40\n",
            "30/30 [==============================] - 1s 33ms/step - loss: 0.0923 - accuracy: 0.9763 - val_loss: 0.3110 - val_accuracy: 0.8830\n",
            "Epoch 40/40\n",
            "30/30 [==============================] - 1s 35ms/step - loss: 0.0887 - accuracy: 0.9773 - val_loss: 0.3143 - val_accuracy: 0.8826\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.3376 - accuracy: 0.8697\n",
            "[0.3376350402832031, 0.8697199821472168]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction:\n",
        "test_review = test_data[0]\n",
        "prediction = model.predict(np.expand_dims(test_review, axis=0))\n",
        "print(\"Review:\")\n",
        "print(decode_review(test_review))\n",
        "print(\"Prediction: \" + str(prediction[0][0]))\n",
        "print(\"Actual: \" + str(test_labels[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7oR358JWCGS",
        "outputId": "992d8988-0ac8-4b71-8b35-70fe846396cb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 64ms/step\n",
            "Review:\n",
            "<START> please give this one a miss br br <UNK> <UNK> and the rest of the cast rendered terrible performances the show is flat flat flat br br i don't know how michael madison could have allowed this one on his plate he almost seemed to know this wasn't going to work out and his performance was quite <UNK> so all you madison fans give this a miss <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD>\n",
            "Prediction: 0.07236254\n",
            "Actual: 0\n"
          ]
        }
      ]
    }
  ]
}